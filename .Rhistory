#Tirage uniforme iid
U=runif(1,min=0,max=1)
#calcul f/Mg=Vraiemblance/M0
prod((1-pnorm(X[Y==0,]%*%Theta_candid))**(1-Y[Y==0]))/M0
Theta_candid=rnorm(4,0,4)
#Tirage uniforme iid
U=runif(1,min=0,max=1)
#calcul f/Mg=Vraiemblance/M0
prod((1-pnorm(X[Y==0,]%*%Theta_candid))**(1-Y[Y==0]))/M0
Theta_candid=rnorm(4,0,4)
#Tirage uniforme iid
U=runif(1,min=0,max=1)
#calcul f/Mg=Vraiemblance/M0
prod((1-pnorm(X[Y==0,]%*%Theta_candid))**(1-Y[Y==0]))/M0
Theta_candid=rnorm(4,0,4)
#Tirage uniforme iid
U=runif(1,min=0,max=1)
#calcul f/Mg=Vraiemblance/M0
prod((1-pnorm(X[Y==0,]%*%Theta_candid))**(1-Y[Y==0]))/M0
Theta_candid=rnorm(4,0,4)
#Tirage uniforme iid
U=runif(1,min=0,max=1)
#calcul f/Mg=Vraiemblance/M0
prod((1-pnorm(X[Y==0,]%*%Theta_candid))**(1-Y[Y==0]))/M0
Theta_candid=rnorm(4,0,4)
#Tirage uniforme iid
U=runif(1,min=0,max=1)
#calcul f/Mg=Vraiemblance/M0
prod((1-pnorm(X[Y==0,]%*%Theta_candid))**(1-Y[Y==0]))/M0
Theta_candid=rnorm(4,0,4)
#Tirage uniforme iid
U=runif(1,min=0,max=1)
#calcul f/Mg=Vraiemblance/M0
prod((1-pnorm(X[Y==0,]%*%Theta_candid))**(1-Y[Y==0]))/M0
pnorm(X[Y==0,]
X[Y==0,]
X[Y==0,]
pnorm(X[Y==0,]%*%Theta_candid)
X[Y==0,]%*%Theta_candid)
X[Y==0,]%*%Theta_candid
M0=1.01
vraisemblance=function(theta,Y,X){
return(prod(pnorm(X[Y==1,]%*%theta))*prod(1-pnorm(X[Y==0,]%*%theta)))
}
gen=function(Y,X,M0=M_0){
while(TRUE){
#Tirer Theta_candid selon g
Theta_candid=rnorm(4,0,4)
#Tirage uniforme iid
U=runif(1,min=0,max=1)
#calcul f/Mg=Vraiemblance/M0
f_Mg=prod(pnorm(X[Y==1,]%*%Theta_candid))*prod(1-pnorm(X[Y==0,]%*%Theqta_candid))/M0
if(U<=f_Mg){
return(Theta_candid)
}
}
}
gen_ech=function(nb_ech,Y,X,M0=M_0){
out=rep(1,nb_ech)
out=rerun(nb_ech,gen(Y,X,M_0)) %>% unlist()
out <- matrix(out, ncol=4)
return(out)
}
output=gen_ech(100,Y,X)
gen=function(Y,X,M0=M_0){
while(TRUE){
#Tirer Theta_candid selon g
Theta_candid=rnorm(4,0,4)
#Tirage uniforme iid
U=runif(1,min=0,max=1)
#calcul f/Mg=Vraiemblance/M0
f_Mg=prod(pnorm(X[Y==1,]%*%Theta_candid))*prod(1-pnorm(X[Y==0,]%*%Theqta_candid))/M0
if(U<=f_Mg){
return(Theta_candid)
}
}
}
gen(Y,X,M_0)
gen=function(Y,X,M0=M_0){
while(TRUE){
#Tirer Theta_candid selon g
Theta_candid=rnorm(4,0,4)
#Tirage uniforme iid
U=runif(1,min=0,max=1)
#calcul f/Mg=Vraiemblance/M0
f_Mg=prod(pnorm(X[Y==1,]%*%Theta_candid))*prod(1-pnorm(X[Y==0,]%*%Theta_candid))/M0
if(U<=f_Mg){
return(Theta_candid)
}
}
}
gen_ech=function(nb_ech,Y,X,M0=M_0){
out=rep(1,nb_ech)
out=rerun(nb_ech,gen(Y,X,M_0)) %>% unlist()
out <- matrix(out, ncol=4)
return(out)
}
output=gen_ech(100,Y,X)
knitr::opts_chunk$set(echo = TRUE)
any(is.na(music))
#setwd('/Users/admin/Desktop/STA203/Projet/')
setwd('/home/lokmen/Documents/ENSTA/STAT/STA203/DM/STA203')
music=read.table("Music.txt", sep=";")
any(is.na(music))
set.seed(103)
train=sample(c(TRUE,FALSE),n,rep=TRUE,prob=c(2/3,1/3))
?normalize
??normalize
normalize <- function(x){
return((x-min(x))/(max(x)-min(x)))
}
?data.frame
knitr::opts_chunk$set(echo = TRUE)
require(class)
normalize <- function(x){
return((x-min(x))/(max(x)-min(x)))
}
music_norm <- as.data.frame(lapply(music[,-length(music)], normalize))
rm(list = objects())
graphics.off()
#setwd('/Users/admin/Desktop/STA203/Projet/')
setwd('/home/lokmen/Documents/ENSTA/STAT/STA203/DM/STA203')
music=read.table("Music.txt", sep=";")
normalize <- function(x){
return((x-min(x))/(max(x)-min(x)))
}
music_norm <- as.data.frame(lapply(music[,-length(music)], normalize))
music_norm
head((music_norm[train,-length(music_norm)])
)
set.seed(103)
train=sample(c(TRUE,FALSE),n,rep=TRUE,prob=c(2/3,1/3))
rm(list = objects())
graphics.off()
#setwd('/Users/admin/Desktop/STA203/Projet/')
setwd('/home/lokmen/Documents/ENSTA/STAT/STA203/DM/STA203')
music=read.table("Music.txt", sep=";")
nr=nrow(music) ## nr = 6447
music <- subset(music, select=-c(148:167))
ncl=length(music) ## ncl= 172
ncl
train=sample(c(TRUE,FALSE),ncl,rep=TRUE,prob=c(2/3,1/3))
train
train=sample(c(TRUE,FALSE),nrow,rep=TRUE,prob=c(2/3,1/3))
nr=nrow(music) ## nr = 6447
train=sample(c(TRUE,FALSE),nr,rep=TRUE,prob=c(2/3,1/3))
train
normalize <- function(x){
return((x-min(x))/(max(x)-min(x)))
}
music_norm <- as.data.frame(lapply(music[,-length(music)], normalize))
require(class)
head(music_norm[train,length(music_norm)])
pr <- knn(music_norm[train,-length(music_norm)],
music_norm[-train,-length(music_norm)],
cl=music[train,length(music)],k=1)
head(music[train,length(music)])
## On effectue la classification selon knn et on recupere le resultat
knn_class <- knn(music_norm[train,-length(music_norm)],
music_norm[-train,-length(music_norm)],
cl=music[train,length(music)],k=1)
## On regarde la matrice de confusion
table(knn_class,music[-train,length(music)])
## On observe la proportion de prevision correcte
mean(knn_clas==music[-train,length(music)])
## On observe la proportion de prevision correcte
mean(knn_class==music[-train,length(music)])
knitr::opts_chunk$set(echo = TRUE)
rm(list = objects())
knitr::opts_chunk$set(echo = TRUE)
graphics.off()
#setwd('/Users/admin/Desktop/STA203/Projet/')
setwd('/home/lokmen/Documents/ENSTA/STAT/STA203/DM/STA203')
music=read.table("Music.txt", sep=";")
music=read.table("Music.txt", sep=";")
#View(music)
ncl=length(music) ## ncl= 192
nr=nrow(music) ## nr = 6447
music <- subset(music, select=-c(148:167))
ncl=length(music) ## ncl= 172
set.seed(103)
train=sample(c(TRUE,FALSE),nr,rep=TRUE,prob=c(2/3,1/3))
## Fonction de normalisation
normalize <- function(x){
return((x-min(x))/(max(x)-min(x)))
}
## On normalise sur chaque colonne
music_norm <- as.data.frame(lapply(music[,-length(music)], normalize))
## On effectue la classification selon knn et on recupere le resultat
knn_class <- knn(music_norm[train,-length(music_norm)],
music_norm[-train,-length(music_norm)],
cl=music[train,length(music)],k=3)
require(class)
## On effectue la classification selon knn et on recupere le resultat
knn_class <- knn(music_norm[train,-length(music_norm)],
music_norm[-train,-length(music_norm)],
cl=music[train,length(music)],k=3)
## On regarde la matrice de confusion
table(knn_class,music[-train,length(music)])
## On observe la proportion de prevision correcte
mean(knn_class==music[-train,length(music)])
knn_k <- function(k){
knn_class <- knn(music_norm[train,-length(music_norm)],
music_norm[-train,-length(music_norm)],
cl=music[train,length(music)],k=3)
return(mean(knn_class!=music[-train,length(music)]))
}
K_max <- 5
erreur <- unlist(lapply(c(1:K_max),knn_k))
erreur <- unlist(lapply(c(1:K_max),knn_k))
erreur
knitr::opts_chunk$set(echo = TRUE)
#setwd('/Users/admin/Desktop/STA203/Projet/')
setwd('/home/lokmen/Documents/ENSTA/STAT/STA203/DM/STA203')
knitr::opts_chunk$set(echo = TRUE)
music=read.table("Music.txt", sep=";")
#setwd('/Users/admin/Desktop/STA203/Projet/')
setwd('/home/lokmen/Documents/ENSTA/STAT/STA203/DM/STA203')
music=read.table("Music.txt", sep=";")
#View(music)
ncl=length(music) ## ncl= 192
nr=nrow(music) ## nr = 6447
music <- subset(music, select=-c(148:167))
ncl=length(music) ## ncl= 172
set.seed(103)
train=sample(c(TRUE,FALSE),nr,rep=TRUE,prob=c(2/3,1/3))
## Fonction de normalisation
normalize <- function(x){
return((x-min(x))/(max(x)-min(x)))
}
## On normalise sur chaque colonne
music_norm <- as.data.frame(lapply(music[,-length(music)], normalize))
knn_k <- function(k){
knn_class <- knn(music_norm[train,-length(music_norm)],
music_norm[-train,-length(music_norm)],
cl=music[train,length(music)],k=3)
return(mean(knn_class!=music[-train,length(music)]))
}
## On effectue la classification selon knn et on recupere le resultat
knn_class <- knn(music_norm[train,-length(music_norm)],
music_norm[-train,-length(music_norm)],
cl=music[train,length(music)],k=1)
require(class)
## On normalise sur chaque colonne
music_norm <- as.data.frame(lapply(music[,-length(music)], normalize))
require(class)
## On effectue la classification selon knn et on recupere le resultat
knn_class <- knn(music_norm[train,-length(music_norm)],
music_norm[-train,-length(music_norm)],
cl=music[train,length(music)],k=1)
## On regarde la matrice de confusion
table(knn_class,music[-train,length(music)])
## On observe la proportion de prevision correcte
mean(knn_class==music[-train,length(music)])
knn_class <- knn(music[train,-length(music)],
music[-train,-length(music)],
cl=music[train,length(music)],k=1)
## On regarde la matrice de confusion
table(knn_class,music[-train,length(music)])
## On observe la proportion de prevision correcte
mean(knn_class==music[-train,length(music)])
## On observe la proportion de prevision correcte
mean(knn_class!=music[-train,length(music)])
wich(train)
which(train)
length(which(train))
names(music[train,-length(music)])
names(music[train,length(music)])
head(music[train,length(music)])
str(music[train,length(music)])
summary(music[train,length(music)])
music[train,length(music)]
tail(names(music))
names(music[train,length(music)])
names(music[train,$GENRE])
names(music$GENRE[train])
knitr::opts_chunk$set(echo = TRUE)
rm(list = objects())
rm(list = objects())
graphics.off()
#setwd('/Users/admin/Desktop/STA203/Projet/')
setwd('/home/lokmen/Documents/ENSTA/STAT/STA203/DM/STA203')
music=read.table("Music.txt", sep=";")
music=read.table("Music.txt", sep=";")
#View(music)
ncl=length(music) ## ncl= 192
nr=nrow(music) ## nr = 6447
music <- subset(music, select=-c(148:167))
ncl=length(music) ## ncl= 172
require(class)
rm(list = objects())
graphics.off()
#setwd('/Users/admin/Desktop/STA203/Projet/')
setwd('/home/lokmen/Documents/ENSTA/STAT/STA203/DM/STA203')
music=read.table("Music.txt", sep=";")
#View(music)
ncl=length(music) ## ncl= 192
nr=nrow(music) ## nr = 6447
music <- subset(music, select=-c(148:167))
ncl=length(music) ## ncl= 172
set.seed(103)
train=sample(c(TRUE,FALSE),nr,rep=TRUE,prob=c(2/3,1/3))
?cbin
?cbind
?lmtot
??lmtot
?sweep
#valeur des pénalités allant de 10^10 à 10^-2
grid = 10^seq(10, -2, length = 100)
grid
## Fonction de normalisation
normalize <- function(x){
return((x-min(x))/(max(x)-min(x)))
}
## On normalise les observations
music_norm <- as.data.frame(lapply(music[,-length(music)], normalize),music[,length(music)])
## On normalise les observations
music_norm <- as.data.frame(lapply(music[,-length(music)], normalize))
music[,length(music)]
## On normalise les observations
music_norm <- as.data.frame(lapply(music[,-length(music)], normalize),music[,length(music)])
## On normalise les observations
music_norm <- as.data.frame(lapply(music[,-length(music)], normalize))
music_norm
head(music_norm)
y=music$GENRE
## On cree la matrice des observations normalisees
y=music$GENRE
X_norm=model.matrix(y~.,data.frame(music_norm,y))[,-1]
## On cree la matrice des observations normalisees
Y=music$GENRE
X_norm=model.matrix(Y~.,data.frame(music_norm,Y))[,-1]
ridge.fit=glmnet(X_norm,Y,alpha=0,lambda=grid) # alpha=0 pour ridge et standardisation par d?faut
require(glmnet)
## On normalise les observations
music_norm <- as.data.frame(lapply(music[,-length(music)], normalize))
## On cree la matrice des observations normalisees
Y=music$GENRE
X_norm=model.matrix(Y~.,data.frame(music_norm,Y))[,-1]
ridge.fit=glmnet(X_norm,Y,alpha=0,lambda=grid) # alpha=0 pour ridge et standardisation par d?faut
#régression
ridge.fit = glmnet(X_norm, Y, alpha = 0, lambda = grid, family = "binomial", standardize = T)
?glmnet
## On cree la matrice des observations
Y=music$GENRE
X=model.matrix(Y~.,music_norm)[,-1]
# Regression Ridge. standardize = TRUE
ridge.fit = glmnet(X, Y, alpha = 0, lambda = grid, family = "binomial", standardize = TRUE)
plot(ridge.fit)
plot(ridge.fit)
plot(ridge.fit,label = TRUE)
knitr::opts_chunk$set(echo = TRUE)
rm(list = objects())
graphics.off()
#setwd('/Users/admin/Desktop/STA203/Projet/')
setwd('/home/lokmen/Documents/ENSTA/STAT/STA203/DM/STA203')
music=read.table("Music.txt", sep=";")
music=read.table("Music.txt", sep=";")
#View(music)
ncl=length(music) ## ncl= 192
#View(music)
ncl=length(music) ## ncl= 192
nr=nrow(music) ## nr = 6447
music <- subset(music, select=-c(148:167))
ncl=length(music) ## ncl= 172
set.seed(103)
train=sample(c(TRUE,FALSE),nr,rep=TRUE,prob=c(2/3,1/3))
## Fonction de normalisation
normalize <- function(x){
return((x-min(x))/(max(x)-min(x)))
}
set.seed(314)
set.seed(314) ## La vlidation croisee divise l'échantillon aleatoirement
?cv.glmnet
require(glmnet)
?cv.glmnet
## Plage des Penalites Allant de 10^10 à 10^-2
grid = 10^seq(10, -2, length = 100)
## On cree la matrice des observations
Y=music$GENRE[train]
X=model.matrix(Y~.,music_norm)[train,-1]
## On normalise sur chaque colonne
music_norm <- as.data.frame(lapply(music[,-length(music)], normalize))
## On cree la matrice des observations
Y=music$GENRE[train]
X=model.matrix(Y~.,music_norm)[train,]
## On cree la matrice des observations
Y=music$GENRE[train]
X=model.matrix(Y~.,music_norm)[train,]
model.matrix(Y~.,music_norm)
X=model.matrix(Y~.,music_norm[train,])
## Regression Ridge. standardize = TRUE permet de normaliser les observations
## Alpha = 0 indique la penalisation ridge
## La variable reponse est categorielle avec deux niveaux donc on prend family = "binomial"
ridge.fit = glmnet(X, Y, alpha = 0, lambda = grid, family = "binomial", standardize = TRUE)
plot(ridge.fit,label = TRUE)
knitr::opts_chunk$set(echo = TRUE)
setwd('/home/lokmen/Documents/ENSTA/STAT/STA212/STA212DM')
music=read.csv("oj.csv", header = TRUE)
OJ=read.csv("oj.csv", header = TRUE)
View(OJ)
str(OJ)
summary(OJ)
head(OJ$WeekofPurchase)
summary(OJ$WeekofPurchase)
head(OJ$StoreID)
summary(OJ$StoreID)
boxplot(OJ$StoreID)
plot(OJ$StoreID)
head(OJ$PriceCH)
summary(OJ$PriceCH)
plot(OJ$PriceCH)
boxplot(OJ$PriceCH)
summary(OJ$PriceCH)
head(OJ$PriceMM)
summary(OJ$PriceMM)
plot(OJ$PriceMM)
plot(OJ$PriceCH)
head(OJ$DiscCH)
summary(OJ$DiscCH)
boxplot(OJ$DiscCH)
plot(OJ$DiscCH)
table(OJ$DiscCH)
head(OJ$DiscMM)
summary(OJ$DiscMM)
boxplot(OJ$DiscMM)
plot(OJ$DiscMM)
table(OJ$DiscMM)
head(OJ$SpecialCH)
summary(OJ$SpecialCH)
boxplot(OJ$SpecialCH)
plot(OJ$SpecialCH)
table(OJ$SpecialCH)
plot(OJ$SpecialCH)
table(OJ$SpecialCH)
head(OJ$StoreID)
head(OJ$SpecialCH)
summary(OJ$SpecialCH)
boxplot(OJ$SpecialCH)
plot(OJ$SpecialCH)
table(OJ$SpecialCH)
head(OJ$SalePriceMM)
summary(OJ$SalePriceMM)
boxplot(OJ$SalePriceMM)
plot(OJ$SalePriceMM)
table(OJ$SpecialMM)
table(OJ$SpecialMM)
plot(OJ$SalePriceMM)
head(OJ$SpecialMM)
summary(OJ$SpecialMM)
boxplot(OJ$SpecialMM)
plot(OJ$SpecialMM)
table(OJ$SpecialMM)
head(OJ$LoyalCH)
summary(OJ$LoyalCH)
head(OJ$LoyalCH)
summary(OJ$LoyalCH)
boxplot(OJ$LoyalCH)
plot(OJ$LoyalCH)
table(OJ$LoyalCH)
head(OJ$SalePriceMM)
summary(OJ$SalePriceMM)
boxplot(OJ$SalePriceMM)
plot(OJ$SalePriceMM)
table(OJ$SalePriceMM)
length(table(OJ$SalePriceMM))
head(OJ$SalePriceMM)
summary(OJ$SalePriceMM)
boxplot(OJ$SalePriceMM)
plot(OJ$SalePriceMM)
length(table(OJ$SalePriceMM))
head(OJ$SalePriceMM)
head(OJ$PriceMM)
summary(OJ$SalePriceMM)
summary(OJ$PriceMM)
head(OJ$PriceDiff)
summary(OJ$PriceDiff)
boxplot(OJ$PriceDiff)
plot(OJ$PriceDiff)
table(OJ$PriceDiff)
head(OJ$Store7)
summary(OJ$Store7)
boxplot(OJ$Store7)
plot(OJ$Store7)
head(OJ$PctDiscCH)
summary(OJ$PctDiscCH)
boxplot(OJ$PctDiscCH)
plot(OJ$PctDiscCH)
table(OJ$PctDiscCH)
summary(OJ$DiscCH/OJ$PctDiscCH)
plot(OJ$DiscCH/OJ$PctDiscCH)
plot(OJ$DiscMM/OJ$PctDiscMM)
head(OJ$STORE)
summary(OJ$STORE)
boxplot(OJ$STORE)
plot(OJ$STORE)
table(OJ$STORE)
head(OJ$ListPriceDiff)
summary(OJ$ListPriceDiff)
boxplot(OJ$ListPriceDiff)
plot(OJ$ListPriceDiff)
plot(OJ$SpecialCH)
OJ$SpecialMM <- as.factor(OJ$SpecialMM)
plot(OJ$SpecialMM)
OJ$SpecialCH <- as.factor(OJ$SpecialCH)
OJ$STORE <- as.factor(OJ$STORE+1)
plot(OJ$STORE)
summary(OJ$PriceDiff)
summary(OJ$PriceDiff)
summary(OJ$SalePriceMM-OJ$SalePriceCH)
OJ <- subset(OJ, select=-PriceDiff)
length(OJ)
